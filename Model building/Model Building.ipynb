{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Keras Library\n",
    "import keras\n",
    "#import ImageDataGenerator class from keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c51eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define The Parameters /Arguments For ImageDataGenerator Class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bd64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to trainset.\n",
    "x_train = train_datagen.flow_from_directory(r\"D:\\Anaconda\\Main project\\Dataset\\train_set\",target_size = (128,128),batch_size = 32,class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41f777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to testset.\n",
    "x_test = test_datagen.flow_from_directory(r\"D:\\Anaconda\\Main project\\Dataset\\test_set\",target_size = (128,128),batch_size = 32,class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5741840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model building libraries...\n",
    "#To define linear intialisation import sequential\n",
    "from keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from keras.layers import Dense\n",
    "#To create convolution kernal import convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "#import Maxpooling layer\n",
    "from keras.layers import MaxPooling2D\n",
    "#import flatten layer\n",
    "from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed408f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705c016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add convolutional layer\n",
    "model.add (Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b690f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49d9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add flatten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1eeafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hidden layer\n",
    "model.add(Dense(150,activation='relu'))\n",
    "#add output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e53c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the learning process\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0dfdc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 84s 6s/step - loss: 1.3675 - accuracy: 0.7752 - val_loss: 0.4069 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 89s 7s/step - loss: 0.2862 - accuracy: 0.8922 - val_loss: 0.1714 - val_accuracy: 0.9008\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.3521 - accuracy: 0.8784 - val_loss: 0.1822 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.2194 - accuracy: 0.8968 - val_loss: 0.0568 - val_accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.1690 - accuracy: 0.9312 - val_loss: 0.1993 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 75s 5s/step - loss: 0.2665 - accuracy: 0.8807 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 66s 5s/step - loss: 0.1994 - accuracy: 0.9220 - val_loss: 0.0899 - val_accuracy: 0.9669\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.1585 - accuracy: 0.9335 - val_loss: 0.0656 - val_accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 70s 5s/step - loss: 0.1650 - accuracy: 0.9220 - val_loss: 0.0529 - val_accuracy: 0.9752\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 56s 4s/step - loss: 0.1603 - accuracy: 0.9312 - val_loss: 0.1321 - val_accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f800965e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96e2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"forest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a4ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load_model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image class from keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a5899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "model = load_model(\"forest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2accf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img(r'D:\\Anaconda\\Main project\\Dataset\\test_set\\with fire\\GettyImages_482867948.0.jpg')\n",
    "x=image.img_to_array(img)\n",
    "res = cv2.resize(x, dsize=(128,128),interpolation=cv2.INTER_CUBIC)\n",
    "x=np.expand_dims(res,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999f4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b057e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
